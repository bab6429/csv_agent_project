"""
Agent orchestrateur qui route les questions vers les agents sp√©cialis√©s
Utilise un LLM pour un routing intelligent
"""
import os
import time
import json
from typing import Optional, List, Dict, Any
import pandas as pd
from csv_tools import CSVTools
from .time_series_agent import TimeSeriesAgent
from .transformation_agent import TransformationAgent
from .data_viz_agent import DataVizAgent
from .plot_commentary_agent import PlotCommentaryAgent
from config import Config
from llm_factory import get_llm


class OrchestratorAgent:
    """
    Agent principal qui orchestre les agents sp√©cialis√©s
    Route les questions vers l'agent appropri√© selon le type de question
    Utilise un LLM pour un routing intelligent et contextuel
    """
    
    def __init__(self, csv_path: str, api_key: Optional[str] = None, verbose: bool = True):
        """
        Initialise l'agent orchestrateur
        
        Args:
            csv_path: Chemin vers le fichier CSV
            api_key: Cl√© API Google (optionnel)
            verbose: Si True, affiche les √©tapes de raisonnement
        """
        self.csv_path = csv_path
        self.verbose = verbose
        self.last_llm_call_time = 0
        self.llm_counter = {"count": 0}
        
        # Initialisation du LLM pour le routing (l√©ger, rapide)
        # Utilise Ollama si disponible, sinon fallback vers Gemini
        print("ü§ñ Initialisation du LLM de routing...")
        try:
            self.routing_llm = get_llm(
                model_name=Config.MODEL_NAME,
                temperature=0,  # D√©terministe pour le routing/plan
                max_output_tokens=1000,  # Plus de marge pour le JSON de plan
                max_retries=2,
                api_key=api_key,
                verbose=verbose
            )
        except ValueError as e:
            # Si ni Ollama ni Gemini ne sont disponibles, on essaie quand m√™me
            # avec Gemini en for√ßant la cl√© API
            if api_key:
                os.environ["GOOGLE_API_KEY"] = api_key
            raise ValueError(
                f"Impossible d'initialiser un LLM. {str(e)}\n"
                "Solutions:\n"
                "1. Installez et d√©marrez Ollama (recommand√© pour usage local)\n"
                "2. D√©finissez GOOGLE_API_KEY dans .env ou passez-la en param√®tre"
            )
        
        # Initialisation des outils CSV (partag√©s par tous les agents)
        print("üîß Initialisation des outils d'analyse...")
        self.csv_tools = CSVTools(csv_path)
        
        # Initialisation des agents sp√©cialis√©s
        print("ü§ñ Initialisation des agents sp√©cialis√©s...")
        self.time_series_agent = TimeSeriesAgent(
            csv_tools=self.csv_tools,
            api_key=api_key,
            verbose=verbose,
            llm_counter=self.llm_counter,
        )
        
        self.transformation_agent = TransformationAgent(
            csv_tools=self.csv_tools,
            api_key=api_key,
            verbose=verbose,
            llm_counter=self.llm_counter,
        )

        self.data_viz_agent = DataVizAgent(
            csv_tools=self.csv_tools,
            api_key=api_key,
            verbose=verbose,
            llm_counter=self.llm_counter,
        )

        self.plot_commentary_agent = PlotCommentaryAgent(
            api_key=api_key,
            verbose=verbose,
            llm_counter=self.llm_counter,
        )
        
        print("‚úÖ Orchestrateur pr√™t !\n")
    
    def _plan_agents(self, question: str) -> List[Dict[str, Any]]:
        """
        Planifie 1 √† 3 √©tapes avec les agents disponibles.
        Retour: liste de dicts {agent, instruction}
        """
        current_time = time.time()
        time_since_last_call = current_time - self.last_llm_call_time
        if time_since_last_call < Config.LLM_REQUEST_DELAY:
            time.sleep(Config.LLM_REQUEST_DELAY - time_since_last_call)
        self.last_llm_call_time = time.time()

        agents_desc = (
            "Agents disponibles:\n"
            "- transformation: structure, stats, valeurs manquantes, corr√©lations, aper√ßu.\n"
            "- time_series: pr√©paration (fusion date/heure), tendances, moyennes mobiles, agr√©gations temporelles, anomalies.\n"
            "- visualization: trac√©s (courbe, scatter, bar, hist, heatmap corr), avec colonnes r√©elles.\n"
            "- plot_commentary: commente un graphique √† partir du r√©sum√© JSON produit par visualization.\n"
        )
        prompt = (
            "Tu es un planificateur. Propose un plan de 1 √† 3 √©tapes pour r√©pondre √† la question.\n"
            f"{agents_desc}\n"
            "R√®gles de planification:\n"
            "- IMPORTANT: Si l'utilisateur demande un sous-ensemble de donn√©es (ex: une plage de dates, une cat√©gorie, un mois pr√©cis), la PREMI√àRE √©tape DOIT √™tre d'utiliser un outil de filtrage ('filter_data' ou 'filter_by_date') via l'agent 'transformation' ou 'time_series'.\n"
            "- Simplement afficher les donn√©es avec 'get_head' n'est PAS suffisant pour que les √©tapes suivantes (comme la visualisation) en profitent.\n"
            "- N'ajoute une √©tape 'visualization' QUE si l'utilisateur demande EXPLICITEMENT un graphique/trac√©/courbe/plot/heatmap/histogramme.\n"
            "- L'agent 'visualization' utilisera automatiquement les donn√©es filtr√©es par les √©tapes pr√©c√©dentes.\n"
            "- Ajoute TOUJOURS une √©tape 'plot_commentary' √† la fin pour fournir une petite analyse (5-8 lignes) bas√©e sur les r√©sultats pr√©c√©dents.\n"
            "Formate en JSON strict: {\"steps\": [{\"agent\": \"...\", \"instruction\": \"...\"}, ...]}\n"
            "- agent ‚àà {transformation, time_series, visualization, plot_commentary}\n"
            "- instruction: consigne concise en fran√ßais.\n"
            "- Pas de texte hors JSON.\n"
            f"Question: {question}"
        )
        try:
            self.llm_counter["count"] += 1
            resp = self.routing_llm.invoke(prompt)
            content = resp.content if hasattr(resp, "content") else str(resp)
            if self.verbose:
                print(f"üìú Plan LLM (brut): {content!r}")

            # Nettoyage: retirer fences ```json ... ``` et extraire le premier objet JSON
            cleaned = (content or "").strip()
            if cleaned.startswith("```"):
                # enl√®ve la premi√®re ligne ```json / ``` et la derni√®re ```
                cleaned = cleaned.strip("`").strip()
            # Extraire le premier {...} si du texte s'est gliss√©
            if "{" in cleaned and "}" in cleaned:
                cleaned = cleaned[cleaned.find("{"): cleaned.rfind("}") + 1]

            plan = json.loads(cleaned)
            steps = plan.get("steps", [])
            if not isinstance(steps, list) or not steps:
                raise ValueError("steps manquant")
            valid = []
            for step in steps[:3]:
                agent = step.get("agent", "").strip().lower()
                instr = step.get("instruction", "").strip()
                if agent in ["transformation", "time_series", "visualization", "plot_commentary"] and instr:
                    valid.append({"agent": agent, "instruction": instr})
            if not valid:
                raise ValueError("steps invalides")
            return valid
        except Exception as e:
            if self.verbose:
                print(f"‚ö†Ô∏è Planification LLM √©chou√©e ({e}), fallback transformation.")
            return [{"agent": "transformation", "instruction": "R√©ponds √† la question de l'utilisateur."}]

    def _synthesize_response(self, question: str, full_context: str) -> str:
        """
        Utilise le LLM pour synth√©tiser la r√©ponse finale √† partir de tout le contexte.
        Filtre le bavardage inutile et ne garde que la valeur ajout√©e.
        """
        prompt = (
            "Tu es l'orchestrateur final d'un syst√®me multi-agents d'analyse de donn√©es.\n"
            "Ta t√¢che est de produire une r√©ponse PROPRE, CONCISE et PROFESSIONNELLE √† l'utilisateur.\n\n"
            "R√àGLES DE SYNTH√àSE :\n"
            "1. Supprime tout le 'bavardage' interne des agents (ex: 'Je vais maintenant...', '√âtape 1 termin√©e', 'Vous pouvez utiliser...').\n"
            "2. Garde UNIQUEMENT la r√©ponse finale √† la question, les statistiques importantes et les tableaux de donn√©es s'ils sont pertinents.\n"
            "3. IMPORTANT : Garde les marqueurs de graphiques (PLOT_ID_START/END et PLOT_SUMMARY_START/END) EXACTEMENT tels quels, sans les modifier. Ils sont cruciaux pour l'affichage.\n"
            "4. Si une analyse (commentaire) est pr√©sente, fusionne-la intelligemment avec la r√©ponse.\n"
            "5. R√©ponds TOUJOURS en fran√ßais.\n"
            "6. Ne mentionne pas les noms techniques des agents (ex: 'L'agent transformation dit...'). Pr√©sente les faits directement.\n\n"
            f"Question de l'utilisateur : {question}\n\n"
            f"Contenu brut des agents :\n{full_context}\n\n"
            "R√©ponse synth√©tis√©e :"
        )
        
        try:
            self.llm_counter["count"] += 1
            resp = self.routing_llm.invoke(prompt)
            final_text = resp.content if hasattr(resp, "content") else str(resp)
            return final_text.strip()
        except Exception as e:
            if self.verbose:
                print(f"‚ö†Ô∏è Synth√®se √©chou√©e ({e}), retour au mode concat√©nation.")
            return None

    def query(self, question: str) -> str:
        """
        Ex√©cute 1 √† 3 agents en s√©quence selon un plan LLM.
        Le texte produit par chaque agent est pass√© en contexte au suivant.
        """
        # R√©initialiser les filtres au d√©but de chaque nouvelle question
        self.csv_tools.reset_filter()
        
        steps = self._plan_agents(question)
        context_text = ""
        last_answer = ""
        viz_answer = ""
        commentary_answer = ""

        agent_map = {
            "transformation": self.transformation_agent,
            "time_series": self.time_series_agent,
            "visualization": self.data_viz_agent,
            "plot_commentary": self.plot_commentary_agent,
        }

        for idx, step in enumerate(steps, start=1):
            agent_name = step["agent"]
            instruction = step["instruction"]
            agent = agent_map.get(agent_name)
            if agent is None:
                continue

            composed_question = (
                f"Contexte des √©tapes pr√©c√©dentes:\n{context_text}\n\n"
                f"Instruction: {instruction}\n\n"
                f"Question utilisateur: {question}"
            )
            if self.verbose:
                print(f"‚û°Ô∏è √âtape {idx}: {agent_name} avec instruction '{instruction}'")
            if agent_name == "plot_commentary":
                # On attend que le contexte contienne PLOT_SUMMARY (JSON) produit par visualization ou des stats
                analysis_prompt = (
                    "Tu es un analyste data. On te fournit le contexte des √©tapes pr√©c√©dentes.\n"
                    "Donne une analyse courte (5-8 lignes max) des r√©sultats : tendances, extr√™mes, relations, et ce que √ßa implique pour la question.\n"
                    "Si un PLOT_SUMMARY est pr√©sent, base-toi dessus. Sinon, base-toi sur les statistiques et donn√©es textuelles fournies.\n\n"
                    f"{composed_question}"
                )
                answer = agent.query(analysis_prompt)
                commentary_answer = answer
            else:
                answer = agent.query(composed_question)
                if agent_name == "visualization":
                    viz_answer = answer

            context_text += f"\n\n[√âtape {idx} - {agent_name}]:\n{answer}"
            last_answer = answer

        if not last_answer:
            last_answer = self.transformation_agent.query(question)

        # Tentative de synth√®se intelligente
        synthesized = self._synthesize_response(question, context_text)
        if synthesized:
            return synthesized

        # Fallback : construction manuelle si la synth√®se √©choue
        previous_outputs = []
        for idx, step in enumerate(steps, start=1):
            if step["agent"] in ["visualization", "plot_commentary"]:
                continue
            marker = f"[√âtape {idx} - {step['agent']}]:"
            if marker in context_text:
                start_idx = context_text.find(marker) + len(marker)
                next_marker = f"[√âtape {idx + 1} -"
                if next_marker in context_text:
                    end_idx = context_text.find(next_marker)
                    agent_output = context_text[start_idx:end_idx].strip()
                else:
                    agent_output = context_text[start_idx:].strip()
                if agent_output:
                    previous_outputs.append(agent_output)
        
        final_response = ""
        if previous_outputs:
            final_response = "\n\n".join(previous_outputs) + "\n\n"
        
        if viz_answer:
            final_response += viz_answer
        elif not final_response and last_answer and last_answer != commentary_answer:
            final_response = last_answer

        if commentary_answer:
            final_response += f"\n\nüìù Analyse:\n{commentary_answer}"
        
        return final_response.strip() if final_response else last_answer
    
    def get_dataframe(self):
        """Retourne le DataFrame pandas pour un acc√®s direct si n√©cessaire"""
        return self.csv_tools.df

    def get_llm_iterations(self) -> int:
        """Retourne le nombre d'appels LLM effectu√©s depuis le chargement de l'agent"""
        return int(self.llm_counter.get("count", 0))

