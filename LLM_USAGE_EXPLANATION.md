# ğŸ“š Explication : Quand les LLM sont utilisÃ©s dans le systÃ¨me

## ğŸ¯ Vue d'ensemble

Le systÃ¨me utilise des **LLM (Large Language Models)** Ã  **3 niveaux diffÃ©rents** pour traiter les questions des utilisateurs. Voici une explication claire de chaque utilisation.

---

## ğŸ”„ Flux complet avec les LLM

```
Question Utilisateur
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. OrchestratorAgent (LLM #1)      â”‚
â”‚    â†’ Routing intelligent            â”‚
â”‚    â†’ DÃ©cide quel agent utiliser     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚
       â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. TimeSeriesâ”‚  â”‚ 2. Transform â”‚
â”‚    Agent     â”‚  â”‚    Agent     â”‚
â”‚  (LLM #2)    â”‚  â”‚  (LLM #2)    â”‚
â”‚              â”‚  â”‚              â”‚
â”‚ Pattern ReActâ”‚  â”‚ Pattern ReActâ”‚
â”‚ + Outils     â”‚  â”‚ + Outils     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1ï¸âƒ£ LLM de l'OrchestratorAgent (Routing)

### **Quand est-il utilisÃ© ?**
- **Ã€ chaque question** de l'utilisateur
- **Avant** que la question soit traitÃ©e par un agent spÃ©cialisÃ©
- **Une seule fois** par question

### **RÃ´le :**
DÃ©cider quel agent spÃ©cialisÃ© doit traiter la question

### **Comment Ã§a fonctionne :**
```python
# Dans orchestrator_agent.py
def _detect_agent_type(self, question: str) -> str:
    # Le LLM analyse la question
    routing_prompt = f"""Analyse cette question et dÃ©termine quel agent utiliser...
    Question: "{question}"
    Agents: time_series ou transformation"""
    
    response = self.routing_llm.invoke(routing_prompt)
    # Retourne "time_series" ou "transformation"
```

### **Exemple :**
```
Question: "Quelle est la tendance des ventes ?"
    â†“
LLM Orchestrateur analyse â†’ "time_series"
    â†“
Route vers TimeSeriesAgent
```

### **CaractÃ©ristiques :**
- âœ… **Rapide** : max_output_tokens=50 (trÃ¨s court)
- âœ… **DÃ©terministe** : temperature=0
- âœ… **Simple** : Juste choisir entre 2 options

---

## 2ï¸âƒ£ LLM des Agents SpÃ©cialisÃ©s (Traitement)

### **Quand sont-ils utilisÃ©s ?**
- **AprÃ¨s** le routing par l'orchestrateur
- **Pour chaque question** routÃ©e vers l'agent
- **Plusieurs fois** si nÃ©cessaire (pattern ReAct)

### **RÃ´le :**
Traiter la question en utilisant le pattern ReAct (Reasoning + Acting)

### **Agents concernÃ©s :**
1. **TimeSeriesAgent** - Pour les questions temporelles
2. **TransformationAgent** - Pour les questions gÃ©nÃ©rales/stats

### **Comment Ã§a fonctionne (Pattern ReAct) :**

```
Question: "Calcule la tendance des ventes"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM TimeSeriesAgent                 â”‚
â”‚                                     â”‚
â”‚ Thought: "Je dois calculer la      â”‚
â”‚          tendance de la colonne    â”‚
â”‚          ventes"                    â”‚
â”‚                                     â”‚
â”‚ Action: calculate_trend             â”‚
â”‚ Action Input: ventes                â”‚
â”‚                                     â”‚
â”‚ Observation: [rÃ©sultat de l'outil] â”‚
â”‚                                     â”‚
â”‚ Thought: "J'ai la rÃ©ponse"          â”‚
â”‚ Final Answer: "La tendance est..."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Exemple concret :**

```python
# Dans time_series_agent.py
def query(self, question: str) -> str:
    # Le LLM utilise le pattern ReAct
    response = self.agent_executor.invoke({"input": question})
    # Le LLM peut appeler plusieurs outils en boucle
    # Thought â†’ Action â†’ Observation â†’ Thought â†’ Action â†’ ...
    # Jusqu'Ã  trouver la rÃ©ponse finale
```

### **CaractÃ©ristiques :**
- âœ… **ItÃ©ratif** : Peut faire plusieurs actions (max 3-4)
- âœ… **Avec outils** : AccÃ¨s Ã  des outils spÃ©cialisÃ©s
- âœ… **Contextuel** : Comprend le contexte de la question
- âœ… **Prompt spÃ©cialisÃ©** : Chaque agent a son propre prompt optimisÃ©

---

## ğŸ“Š RÃ©sumÃ© : Utilisation des LLM

| Ã‰tape | LLM UtilisÃ© | Quand | RÃ´le | Nombre d'appels |
|-------|-------------|-------|------|-----------------|
| **1. Routing** | OrchestratorAgent | Ã€ chaque question | Choisir l'agent | **1 fois** |
| **2. Traitement** | TimeSeriesAgent OU TransformationAgent | AprÃ¨s routing | Traiter la question | **1-4 fois** (ReAct) |

---

## ğŸ”¢ Nombre total d'appels LLM par question

### **Cas simple (1 action) :**
```
Question â†’ Orchestrator LLM (1) â†’ Agent LLM (1) = **2 appels LLM**
```

### **Cas complexe (3 actions) :**
```
Question â†’ Orchestrator LLM (1) â†’ Agent LLM (3) = **4 appels LLM**
```

---

## ğŸ’¡ Pourquoi cette architecture ?

### **Avantages :**
1. **Routing intelligent** : Le LLM comprend le contexte, pas juste des mots-clÃ©s
2. **SpÃ©cialisation** : Chaque agent a un prompt optimisÃ© pour son domaine
3. **EfficacitÃ©** : Les prompts sont courts et ciblÃ©s
4. **FlexibilitÃ©** : Le routing s'adapte aux questions ambiguÃ«s

### **Exemple de routing intelligent :**
```
Question: "Les ventes augmentent-elles ?"
    â†“
LLM Orchestrateur comprend que c'est une question sur tendance
    â†“
Route vers TimeSeriesAgent (mÃªme sans mot-clÃ© explicite)
```

---

## ğŸ¯ Points clÃ©s Ã  retenir

1. **3 LLM au total** dans le systÃ¨me :
   - 1 pour le routing (OrchestratorAgent)
   - 2 pour le traitement (TimeSeriesAgent, TransformationAgent)

2. **Chaque question** dÃ©clenche :
   - 1 appel LLM pour le routing
   - 1-4 appels LLM pour le traitement (selon complexitÃ©)

3. **Les outils** (CSVTools) ne sont **PAS** des LLM :
   - Ce sont des fonctions Python qui exÃ©cutent du code
   - Exemple : `calculate_trend()` fait une rÃ©gression linÃ©aire

4. **Le pattern ReAct** permet au LLM de :
   - Raisonner (Thought)
   - Agir (Action avec outil)
   - Observer (Observation)
   - RÃ©pÃ©ter jusqu'Ã  la rÃ©ponse finale

---

## ğŸ” Exemple complet de flux

```
Utilisateur: "Quelle est la tendance des ventes sur 6 mois ?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Orchestrateur (Appel #1)        â”‚
â”‚ Analyse: "tendance" + "6 mois"      â”‚
â”‚ DÃ©cision: time_series                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM TimeSeriesAgent (Appel #2)      â”‚
â”‚ Thought: "Je dois calculer tendance"â”‚
â”‚ Action: calculate_trend              â”‚
â”‚ Input: ventes                        â”‚
â”‚ Observation: "Tendance: +5.2%"      â”‚
â”‚ Thought: "J'ai la rÃ©ponse"           â”‚
â”‚ Final Answer: "La tendance est..."   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
RÃ©ponse Ã  l'utilisateur
```

**Total : 2 appels LLM** (1 routing + 1 traitement)

---

## ğŸ“ Code de rÃ©fÃ©rence

- **OrchestratorAgent LLM** : `agents/orchestrator_agent.py` ligne 46-51
- **TimeSeriesAgent LLM** : `agents/time_series_agent.py` ligne 40-45
- **TransformationAgent LLM** : `agents/transformation_agent.py` ligne 40-45

---

## â“ Questions frÃ©quentes

**Q: Pourquoi ne pas utiliser un seul LLM avec tous les outils ?**
R: Les prompts seraient trop longs, l'agent serait confus, et les performances se dÃ©graderaient.

**Q: Le routing pourrait-il Ãªtre fait sans LLM ?**
R: Oui, mais le LLM comprend mieux le contexte. Ex: "Les ventes augmentent ?" â†’ comprend que c'est une tendance.

**Q: Combien Ã§a coÃ»te en tokens ?**
R: Routing ~100 tokens, Traitement ~500-2000 tokens selon complexitÃ©. Total ~600-2100 tokens par question.

